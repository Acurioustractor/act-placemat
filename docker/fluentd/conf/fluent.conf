# Fluentd Configuration for ACT Placemat Intelligence Hub
# Australian-compliant log aggregation and processing

# Input sources
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  tag docker.*
</source>

<source>
  @type http
  port 9880
  bind 0.0.0.0
  cors_allow_origins ["*"]
  add_http_headers true
  add_remote_addr true
</source>

<source>
  @type tail
  path /app/logs/intelligence-hub/*.log
  pos_file /fluentd/log/intelligence-hub.log.pos
  tag intelligence.hub
  format json
  time_key timestamp
  time_format %Y-%m-%dT%H:%M:%S.%L%z
  keep_time_key true
  read_from_head true
  refresh_interval 5
</source>

<source>
  @type tail
  path /var/log/nginx/intelligence-hub.access.log
  pos_file /fluentd/log/nginx-access.log.pos
  tag nginx.access
  format nginx
  time_format %d/%b/%Y:%H:%M:%S %z
  keep_time_key true
</source>

<source>
  @type tail
  path /var/log/nginx/intelligence-hub.error.log
  pos_file /fluentd/log/nginx-error.log.pos
  tag nginx.error
  format multiline
  format_firstline /^\d{4}\/\d{2}\/\d{2} \d{2}:\d{2}:\d{2}/
  format1 /^(?<time>\d{4}\/\d{2}\/\d{2} \d{2}:\d{2}:\d{2}) \[(?<log_level>\w+)\] (?<message>.*)/
  time_format %Y/%m/%d %H:%M:%S
</source>

<source>
  @type prometheus
  bind 0.0.0.0
  port 24231
  metrics_path /metrics
</source>

<source>
  @type monitor_agent
  bind 0.0.0.0
  port 24220
</source>

# Filters for Australian compliance and enhancement

<filter **>
  @type record_modifier
  <record>
    hostname ${hostname}
    tag ${tag}
    data_residency Australia
    compliance_framework Australian-Privacy-Act
    timezone Australia/Sydney
    processed_at ${time}
    country_code AU
    platform ACT-Placemat-Intelligence-Hub
  </record>
</filter>

<filter intelligence.**>
  @type record_modifier
  <record>
    component intelligence-hub
    service_type multi-agent-orchestration
    australian_processing true
    democratic_governance enabled
  </record>
</filter>

<filter nginx.**>
  @type record_modifier
  <record>
    component reverse-proxy
    service_type web-gateway
    australian_compliance verified
    security_layer enabled
  </record>
</filter>

# PII detection and masking filter
<filter **>
  @type record_modifier
  <record>
    pii_detected false
  </record>
  
  # Mask Australian phone numbers
  replace_keys_value "[{\"key\":\"message\",\"pattern\":\"/\\b04\\d{2}\\s?\\d{3}\\s?\\d{3}\\b/\",\"replacement\":\"04XX-XXX-XXX\"}]"
  
  # Mask ABN numbers
  replace_keys_value "[{\"key\":\"message\",\"pattern\":\"/\\b\\d{2}\\s?\\d{3}\\s?\\d{3}\\s?\\d{3}\\b/\",\"replacement\":\"XX-XXX-XXX-XXX\"}]"
  
  # Mask email addresses
  replace_keys_value "[{\"key\":\"message\",\"pattern\":\"/\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b/\",\"replacement\":\"user@domain.tld\"}]"
</filter>

# Security event detection
<filter **>
  @type rewrite_tag_filter
  <rule>
    key message
    pattern /failed|error|unauthorized|forbidden|attack|malicious/i
    tag security.${tag}
  </rule>
  <rule>
    key status
    pattern /^[45]\d{2}$/
    tag error.${tag}
  </rule>
</filter>

# Australian business hours classification
<filter **>
  @type record_modifier
  <record>
    business_hours ${strftime("%H").to_i >= 9 && strftime("%H").to_i <= 17 && strftime("%w").to_i >= 1 && strftime("%w").to_i <= 5}
    australian_timezone ${strftime("%Z")}
  </record>
</filter>

# Data classification filter
<filter **>
  @type record_modifier
  <record>
    data_classification internal
  </record>
</filter>

<filter security.**>
  @type record_modifier
  <record>
    data_classification confidential
    security_event true
    requires_investigation true
  </record>
</filter>

# Performance metrics extraction
<filter intelligence.hub>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

# Task processing metrics
<filter intelligence.hub>
  @type record_modifier
  <record>
    task_processing ${record["level"] == "info" && record["message"].include?("task")}
    agent_activity ${record["level"] == "info" && record["message"].include?("agent")}
    workflow_event ${record["level"] == "info" && record["message"].include?("workflow")}
  </record>
</filter>

# Output configurations

# Main log storage (local files with Australian compliance)
<match **>
  @type copy
  
  <store>
    @type file
    path /fluentd/log/aggregated/act-placemat-%Y%m%d
    time_slice_format %Y%m%d
    time_slice_wait 1m
    time_format %Y-%m-%dT%H:%M:%S.%L%z
    compress gzip
    append true
    
    <buffer time>
      @type file
      path /fluentd/log/buffer/
      timekey 3600
      timekey_wait 1m
      chunk_limit_size 64MB
      queue_limit_length 128
      retry_max_interval 30
      retry_forever true
      flush_mode interval
      flush_interval 30s
    </buffer>
    
    <format>
      @type json
      time_key @timestamp
      time_format %Y-%m-%dT%H:%M:%S.%L%z
    </format>
  </store>
  
  # Australian compliance output
  <store>
    @type australian_compliance
    data_residency Australia
    compliance_framework Australian-Privacy-Act
    retention_policy 7-years
  </store>
</match>

# Security events to dedicated storage
<match security.**>
  @type file
  path /fluentd/log/security/security-events-%Y%m%d
  time_slice_format %Y%m%d
  time_slice_wait 1m
  append true
  compress gzip
  
  <buffer time>
    @type file
    path /fluentd/log/security-buffer/
    timekey 900  # 15 minutes for security events
    timekey_wait 30s
    chunk_limit_size 32MB
    queue_limit_length 256
    retry_max_interval 10
    flush_mode interval
    flush_interval 10s
  </buffer>
  
  <format>
    @type json
    time_key @timestamp
    time_format %Y-%m-%dT%H:%M:%S.%L%z
  </format>
</match>

# Error events to dedicated storage  
<match error.**>
  @type file
  path /fluentd/log/errors/error-events-%Y%m%d
  time_slice_format %Y%m%d
  time_slice_wait 1m
  append true
  compress gzip
  
  <buffer time>
    @type file
    path /fluentd/log/error-buffer/
    timekey 1800  # 30 minutes for errors
    timekey_wait 1m
    chunk_limit_size 32MB
    queue_limit_length 128
    retry_max_interval 20
    flush_mode interval
    flush_interval 20s
  </buffer>
  
  <format>
    @type json
    time_key @timestamp
    time_format %Y-%m-%dT%H:%M:%S.%L%z
  </format>
</match>

# Performance metrics to Prometheus (if configured)
# <match intelligence.hub>
#   @type prometheus
#   <metric>
#     name act_placemat_task_processing_total
#     type counter
#     desc Total number of task processing events
#     key task_processing
#   </metric>
#   <metric>
#     name act_placemat_agent_activity_total
#     type counter
#     desc Total number of agent activity events
#     key agent_activity
#   </metric>
#   <metric>
#     name act_placemat_workflow_events_total
#     type counter
#     desc Total number of workflow events
#     key workflow_event
#   </metric>
# </match>

# System configuration
<system>
  log_level info
  workers 2
  
  <log>
    format json
    time_format %Y-%m-%dT%H:%M:%S.%L%z
  </log>
</system>