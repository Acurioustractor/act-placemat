# Task Queue Operations and Logic
# Enqueue/dequeue operations with priority handling and fault tolerance

---
# Task Queue Operations Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: task-queue-operations
  namespace: act-placemat
  labels:
    component: task-queue
    service-type: operations
    data-residency: australia
  annotations:
    description: "Task queue operations service with priority handling"
    compliance.framework: "australian-privacy-act"
spec:
  replicas: 3
  selector:
    matchLabels:
      component: task-queue-operations
      data-residency: australia
  template:
    metadata:
      labels:
        component: task-queue-operations
        data-residency: australia
      annotations:
        compliance.framework: "australian-privacy-act"
        data.classification: "restricted"
        audit.required: "true"
    spec:
      serviceAccountName: task-queue-operations-service
      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        fsGroup: 1001
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: "kubernetes.io/zone"
                operator: In
                values:
                - "australia-southeast1-a"
                - "australia-southeast1-b"
                - "australia-southeast1-c"
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: task-queue-operations
              topologyKey: kubernetes.io/hostname
      containers:
      - name: queue-operations
        image: registry.actplacemat.org.au:5000/act-placemat/task-queue-operations:latest
        imagePullPolicy: Always
        env:
        - name: TZ
          value: "Australia/Sydney"
        - name: DATA_RESIDENCY
          value: "australia"
        - name: COMPLIANCE_FRAMEWORK
          value: "australian-privacy-act"
        - name: REDIS_CLUSTER_HOST
          value: "redis-cluster-service.act-placemat.svc.cluster.local"
        - name: REDIS_CLUSTER_PORT
          value: "6379"
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: redis-cluster-auth
              key: password
        - name: LOG_LEVEL
          value: "INFO"
        - name: QUEUE_BATCH_SIZE
          value: "100"
        - name: PRIORITY_REFRESH_INTERVAL
          value: "300"  # 5 minutes
        - name: HEALTH_CHECK_INTERVAL
          value: "30"
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP
        - name: health
          containerPort: 8081
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /health
            port: health
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: health
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3
        resources:
          limits:
            cpu: 1000m
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1001
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: config
          mountPath: /etc/queue-config
          readOnly: true
        - name: scripts
          mountPath: /etc/queue-scripts
          readOnly: true
      volumes:
      - name: tmp
        emptyDir: {}
      - name: config
        configMap:
          name: task-queue-operations-config
      - name: scripts
        configMap:
          name: task-queue-lua-scripts
      imagePullSecrets:
      - name: registry-credentials
      nodeSelector:
        data-residency: australia

---
# Task Queue Operations Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: task-queue-operations-config
  namespace: act-placemat
  labels:
    component: task-queue
    config-type: operations
    data-residency: australia
  annotations:
    description: "Configuration for task queue operations"
    compliance.framework: "australian-privacy-act"
data:
  operations_config.yaml: |
    # Task Queue Operations Configuration
    queue_operations:
      # Redis connection settings
      redis:
        cluster_mode: true
        connection_pool_size: 20
        connection_timeout: 5000  # milliseconds
        read_timeout: 10000       # milliseconds
        retry_attempts: 3
        retry_delay: 1000         # milliseconds
        
      # Queue configuration
      queues:
        high_priority:
          key: "act:queue:high"
          max_size: 10000
          ttl: 7200  # 2 hours
          
        standard_priority:
          key: "act:queue:standard"
          max_size: 50000
          ttl: 14400  # 4 hours
          
        low_priority:
          key: "act:queue:low"
          max_size: 100000
          ttl: 86400  # 24 hours
          
        processing:
          key: "act:queue:processing"
          timeout: 3600  # 1 hour processing timeout
          
        dead_letter:
          key: "act:queue:dlq"
          retention: 604800  # 7 days
          
        completed:
          key: "act:queue:completed"
          retention: 220752000  # 7 years for Australian compliance
      
      # Priority scoring
      priority_scoring:
        base_multiplier: 1000000
        aging_boost_interval: 300      # 5 minutes
        aging_boost_amount: 50
        max_aging_boost: 500
        deadline_urgency_threshold: 3600  # 1 hour
        deadline_urgency_multiplier: 2.0
        retry_penalty: 100
        max_retry_penalty: 500
        
      # Fault tolerance
      fault_tolerance:
        max_retries: 3
        retry_backoff_base: 1000       # milliseconds
        retry_backoff_multiplier: 2.0
        circuit_breaker_threshold: 10  # failures before circuit opens
        circuit_breaker_timeout: 60000 # milliseconds before retry
        health_check_interval: 30000   # milliseconds
        
      # Australian compliance
      compliance:
        audit_all_operations: true
        data_residency_validation: true
        encryption_required: true
        retention_enforcement: true
        privacy_protection: true
        
      # Performance tuning
      performance:
        batch_size: 100
        concurrent_workers: 10
        queue_scan_interval: 1000      # milliseconds
        metrics_collection_interval: 30000  # milliseconds
        memory_usage_threshold: 0.85   # 85% memory usage alert
        
      # Monitoring and alerting
      monitoring:
        metrics_enabled: true
        health_checks_enabled: true
        performance_logging: true
        error_tracking: true
        compliance_monitoring: true

  # API endpoints configuration
  api_config.yaml: |
    # Task Queue API Configuration
    api:
      server:
        host: "0.0.0.0"
        port: 8080
        read_timeout: 30000    # milliseconds
        write_timeout: 30000   # milliseconds
        idle_timeout: 120000   # milliseconds
        
      endpoints:
        # Task management endpoints
        enqueue:
          path: "/api/v1/tasks/enqueue"
          methods: ["POST"]
          rate_limit: 1000  # requests per minute
          
        dequeue:
          path: "/api/v1/tasks/dequeue"
          methods: ["POST"]
          rate_limit: 10000  # requests per minute
          
        peek:
          path: "/api/v1/tasks/peek"
          methods: ["GET"]
          rate_limit: 5000   # requests per minute
          
        status:
          path: "/api/v1/tasks/{task_id}/status"
          methods: ["GET", "PUT"]
          rate_limit: 2000   # requests per minute
          
        # Queue management endpoints
        queue_stats:
          path: "/api/v1/queues/stats"
          methods: ["GET"]
          rate_limit: 100    # requests per minute
          
        queue_health:
          path: "/api/v1/queues/health"
          methods: ["GET"]
          rate_limit: 500    # requests per minute
          
        # Administrative endpoints
        admin_requeue:
          path: "/api/v1/admin/tasks/requeue"
          methods: ["POST"]
          rate_limit: 10     # requests per minute
          auth_required: true
          
        admin_dlq:
          path: "/api/v1/admin/dlq"
          methods: ["GET", "POST"]
          rate_limit: 50     # requests per minute
          auth_required: true
          
      # Security configuration
      security:
        cors_enabled: true
        cors_origins: ["https://*.actplacemat.org.au"]
        rate_limiting_enabled: true
        auth_required_endpoints: ["/api/v1/admin/*"]
        request_id_header: "X-Request-ID"
        compliance_headers: true
        
      # Australian compliance headers
      compliance_headers:
        - name: "X-Data-Residency"
          value: "australia"
        - name: "X-Compliance-Framework"
          value: "australian-privacy-act"
        - name: "X-Data-Classification"
          value: "restricted"

---
# Task Queue Lua Scripts
apiVersion: v1
kind: ConfigMap
metadata:
  name: task-queue-lua-scripts
  namespace: act-placemat
  labels:
    component: task-queue
    config-type: lua-scripts
    data-residency: australia
  annotations:
    description: "Lua scripts for atomic task queue operations"
    compliance.framework: "australian-privacy-act"
data:
  enqueue.lua: |
    -- Atomic enqueue operation with priority scoring and compliance
    local queue_key = KEYS[1]
    local processing_key = KEYS[2]
    local audit_key = KEYS[3]
    
    local task_data = ARGV[1]
    local priority = tonumber(ARGV[2])
    local current_time = tonumber(ARGV[3])
    local task_id = ARGV[4]
    
    -- Calculate priority score
    local priority_score = (priority * 1000000) + current_time
    
    -- Check for duplicate task
    if redis.call('HEXISTS', processing_key, task_id) == 1 then
        return {-1, "Task already being processed"}
    end
    
    -- Enqueue task with priority score
    local result = redis.call('ZADD', queue_key, priority_score, task_data)
    
    -- Audit logging for Australian compliance
    local audit_entry = string.format(
        '{"timestamp":%d,"operation":"enqueue","task_id":"%s","priority":%d,"queue":"%s","data_residency":"australia"}',
        current_time, task_id, priority, queue_key
    )
    redis.call('ZADD', audit_key, current_time, audit_entry)
    redis.call('EXPIRE', audit_key, 220752000)  -- 7 years retention
    
    -- Return success with queue position
    local queue_position = redis.call('ZREVRANK', queue_key, task_data)
    return {result, queue_position}

  dequeue.lua: |
    -- Atomic dequeue operation with processing state management
    local queue_key = KEYS[1]
    local processing_key = KEYS[2] 
    local audit_key = KEYS[3]
    
    local agent_id = ARGV[1]
    local current_time = tonumber(ARGV[2])
    local processing_timeout = tonumber(ARGV[3])
    
    -- Get highest priority task
    local task_data = redis.call('ZPOPMAX', queue_key)
    if not task_data[1] then
        return {nil, "Queue empty"}
    end
    
    -- Parse task to get task ID
    local task_json = task_data[1]
    local task_id = string.match(task_json, '"task_id":"([^"]+)"')
    
    if not task_id then
        -- Invalid task format, move to DLQ
        redis.call('ZADD', 'act:queue:dlq', current_time, task_json)
        return {nil, "Invalid task format"}
    end
    
    -- Move to processing state
    local processing_info = string.format(
        '{"task_data":%s,"agent_id":"%s","start_time":%d,"timeout":%d}',
        task_json, agent_id, current_time, processing_timeout
    )
    redis.call('HSET', processing_key, task_id, processing_info)
    redis.call('EXPIRE', processing_key, processing_timeout)
    
    -- Audit logging
    local audit_entry = string.format(
        '{"timestamp":%d,"operation":"dequeue","task_id":"%s","agent_id":"%s","queue":"%s","data_residency":"australia"}',
        current_time, task_id, agent_id, queue_key
    )
    redis.call('ZADD', audit_key, current_time, audit_entry)
    
    return {task_json, task_id}

  complete_task.lua: |
    -- Mark task as completed and move to completed queue
    local processing_key = KEYS[1]
    local completed_key = KEYS[2]
    local audit_key = KEYS[3]
    
    local task_id = ARGV[1]
    local agent_id = ARGV[2]
    local current_time = tonumber(ARGV[3])
    local result_data = ARGV[4]
    
    -- Get processing info
    local processing_info = redis.call('HGET', processing_key, task_id)
    if not processing_info then
        return {-1, "Task not found in processing queue"}
    end
    
    -- Remove from processing
    redis.call('HDEL', processing_key, task_id)
    
    -- Create completion record
    local completion_record = string.format(
        '{"task_id":"%s","agent_id":"%s","completion_time":%d,"result":%s,"processing_info":%s}',
        task_id, agent_id, current_time, result_data, processing_info
    )
    
    -- Move to completed queue with 7-year retention for Australian compliance
    redis.call('ZADD', completed_key, current_time, completion_record)
    redis.call('EXPIRE', completed_key, 220752000)  -- 7 years
    
    -- Audit logging
    local audit_entry = string.format(
        '{"timestamp":%d,"operation":"complete","task_id":"%s","agent_id":"%s","data_residency":"australia"}',
        current_time, task_id, agent_id
    )
    redis.call('ZADD', audit_key, current_time, audit_entry)
    
    return {1, "Task completed successfully"}

  fail_task.lua: |
    -- Handle task failure with retry logic or move to DLQ
    local processing_key = KEYS[1]
    local queue_key = KEYS[2]
    local dlq_key = KEYS[3]
    local audit_key = KEYS[4]
    
    local task_id = ARGV[1]
    local agent_id = ARGV[2]
    local current_time = tonumber(ARGV[3])
    local error_message = ARGV[4]
    local max_retries = tonumber(ARGV[5])
    
    -- Get processing info
    local processing_info = redis.call('HGET', processing_key, task_id)
    if not processing_info then
        return {-1, "Task not found in processing queue"}
    end
    
    -- Parse task data from processing info
    local task_data = string.match(processing_info, '"task_data":(%b{})')
    if not task_data then
        return {-1, "Invalid processing info format"}
    end
    
    -- Parse retry count
    local retry_count = tonumber(string.match(task_data, '"retry_count":(%d+)')) or 0
    
    -- Remove from processing
    redis.call('HDEL', processing_key, task_id)
    
    if retry_count < max_retries then
        -- Increment retry count and requeue with penalty
        local updated_task = string.gsub(task_data, '"retry_count":%d+', '"retry_count":' .. (retry_count + 1))
        
        -- Apply retry penalty to priority
        local priority = tonumber(string.match(updated_task, '"priority":(%d+)')) or 5
        local penalty = math.min(retry_count * 100, 500)  -- Max 500 penalty
        local adjusted_priority = math.max(priority - penalty, 1)
        local priority_score = (adjusted_priority * 1000000) + current_time
        
        redis.call('ZADD', queue_key, priority_score, updated_task)
        
        -- Audit retry
        local audit_entry = string.format(
            '{"timestamp":%d,"operation":"retry","task_id":"%s","agent_id":"%s","retry_count":%d,"error":"%s","data_residency":"australia"}',
            current_time, task_id, agent_id, retry_count + 1, error_message
        )
        redis.call('ZADD', audit_key, current_time, audit_entry)
        
        return {1, "Task requeued for retry"}
    else
        -- Max retries exceeded, move to DLQ
        local dlq_record = string.format(
            '{"task_id":"%s","agent_id":"%s","failure_time":%d,"error":"%s","retry_count":%d,"task_data":%s}',
            task_id, agent_id, current_time, error_message, retry_count, task_data
        )
        
        redis.call('ZADD', dlq_key, current_time, dlq_record)
        
        -- Audit DLQ movement
        local audit_entry = string.format(
            '{"timestamp":%d,"operation":"move_to_dlq","task_id":"%s","agent_id":"%s","error":"%s","data_residency":"australia"}',
            current_time, task_id, agent_id, error_message
        )
        redis.call('ZADD', audit_key, current_time, audit_entry)
        
        return {0, "Task moved to DLQ after max retries"}
    end

  cleanup_stale_tasks.lua: |
    -- Clean up stale processing tasks that have exceeded timeout
    local processing_key = KEYS[1]
    local queue_key = KEYS[2]
    local dlq_key = KEYS[3]
    local audit_key = KEYS[4]
    
    local current_time = tonumber(ARGV[1])
    local stale_threshold = tonumber(ARGV[2])
    
    local cleanup_count = 0
    local processing_tasks = redis.call('HGETALL', processing_key)
    
    for i = 1, #processing_tasks, 2 do
        local task_id = processing_tasks[i]
        local processing_info = processing_tasks[i + 1]
        
        -- Parse start time and timeout
        local start_time = tonumber(string.match(processing_info, '"start_time":(%d+)'))
        local timeout = tonumber(string.match(processing_info, '"timeout":(%d+)'))
        
        if start_time and timeout and (current_time - start_time) > timeout then
            -- Task is stale, determine action
            local task_data = string.match(processing_info, '"task_data":(%b{})')
            local retry_count = tonumber(string.match(task_data, '"retry_count":(%d+)')) or 0
            
            -- Remove from processing
            redis.call('HDEL', processing_key, task_id)
            
            if retry_count < 3 then
                -- Requeue with increased retry count
                local updated_task = string.gsub(task_data, '"retry_count":%d+', '"retry_count":' .. (retry_count + 1))
                local priority = tonumber(string.match(updated_task, '"priority":(%d+)')) or 5
                local priority_score = (priority * 1000000) + current_time
                
                redis.call('ZADD', queue_key, priority_score, updated_task)
            else
                -- Move to DLQ
                local dlq_record = string.format(
                    '{"task_id":"%s","failure_time":%d,"reason":"timeout","task_data":%s}',
                    task_id, current_time, task_data
                )
                redis.call('ZADD', dlq_key, current_time, dlq_record)
            end
            
            cleanup_count = cleanup_count + 1
            
            -- Audit cleanup
            local audit_entry = string.format(
                '{"timestamp":%d,"operation":"cleanup_stale","task_id":"%s","data_residency":"australia"}',
                current_time, task_id
            )
            redis.call('ZADD', audit_key, current_time, audit_entry)
        end
    end
    
    return cleanup_count

---
# Task Queue Operations Service Account
apiVersion: v1
kind: ServiceAccount
metadata:
  name: task-queue-operations-service
  namespace: act-placemat
  labels:
    component: task-queue
    role: operations
    data-residency: australia
  annotations:
    description: "Service account for task queue operations"
    compliance.framework: "australian-privacy-act"
automountServiceAccountToken: true

---
# Task Queue Operations Service
apiVersion: v1
kind: Service
metadata:
  name: task-queue-operations-service
  namespace: act-placemat
  labels:
    component: task-queue
    service-type: operations
    data-residency: australia
  annotations:
    description: "Service for task queue operations API"
    compliance.framework: "australian-privacy-act"
spec:
  selector:
    component: task-queue-operations
    data-residency: australia
  ports:
  - name: http
    port: 8080
    targetPort: http
    protocol: TCP
  - name: metrics
    port: 9090
    targetPort: metrics
    protocol: TCP
  - name: health
    port: 8081
    targetPort: health
    protocol: TCP
  type: ClusterIP

---
# Task Queue Operations RBAC Role
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: task-queue-operations-service
  namespace: act-placemat
  labels:
    component: task-queue
    data-residency: australia
  annotations:
    description: "Role for task queue operations"
    compliance.framework: "australian-privacy-act"
rules:
# ConfigMap access for configuration
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "list", "watch"]
# Secret access for Redis authentication
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list", "watch"]
# Event creation for operational logging
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create", "patch"]
# Pod information for health checks
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]

---
# Task Queue Operations Role Binding
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: task-queue-operations-service-binding
  namespace: act-placemat
  labels:
    component: task-queue
    data-residency: australia
  annotations:
    description: "Binds task-queue-operations-service to operations role"
    compliance.framework: "australian-privacy-act"
subjects:
- kind: ServiceAccount
  name: task-queue-operations-service
  namespace: act-placemat
roleRef:
  kind: Role
  name: task-queue-operations-service
  apiGroup: rbac.authorization.k8s.io