# üöÄ Quick Start: Ollama Setup

## ‚úÖ Ollama is Currently Downloading!

The Llama 3.1 8B model is downloading in the background (4.9GB total).

### Check Download Progress

```bash
# In a new terminal window, check status:
ollama list

# You'll see it downloading. When complete, you'll see:
# NAME              ID              SIZE      MODIFIED
# llama3.1:8b       [hash]          4.9 GB    X seconds ago
```

---

## üéØ What to Do While Waiting

### Option 1: Let It Download (Recommended)
The download will continue in the background. Once complete (est. 20-30 min depending on your internet speed), Ollama will be ready to use automatically.

### Option 2: Test with a Tiny Model (Optional)
If you want to test NOW while the big model downloads:

```bash
# Download a tiny 2GB model (much faster)
ollama pull phi3.5

# Test it immediately
ollama run phi3.5 "What is 2+2?"
```

---

## üß™ Test Ollama Once Download Completes

```bash
# Check what models you have
ollama list

# Test the model
ollama run llama3.1:8b "Explain machine learning in one sentence"

# Expected output: A clear, accurate explanation
```

---

## üîß Configure ACT Placemat Backend

Once Ollama is ready, add to your `.env`:

```bash
# Add these lines to: apps/backend/.env
OLLAMA_URL=http://localhost:11434
```

That's it! Your backend will automatically detect and use Ollama for local AI research.

---

## üìä Models to Download (After llama3.1:8b)

Once your first model is ready, you can optionally add more:

```bash
# For faster responses (optional)
ollama pull qwen2.5:7b

# For code analysis (optional)
ollama pull deepseek-coder-v2:16b

# For embedding/search (required for Perplexica)
ollama pull nomic-embed-text
```

---

## ‚úÖ What's Happening Now

1. ‚úÖ Ollama installed
2. ‚úÖ Ollama service running
3. üîÑ llama3.1:8b downloading (54% complete)
4. ‚è≥ Waiting for download to complete

**Next:** Once download completes, we'll set up Perplexica!

---

## üÜò Troubleshooting

**Download stuck?**
```bash
# Cancel and retry
pkill ollama
brew services restart ollama
ollama pull llama3.1:8b
```

**Want to check Ollama logs?**
```bash
tail -f $(brew --prefix)/var/log/ollama.log
```

**Need help?**
The download is working correctly - just wait for it to complete. You can close this terminal and it will continue in the background.
